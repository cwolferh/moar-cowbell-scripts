<% heat = 'false' %>
<% neutron = 'false' %>
<% privateip1 = '192.168.200.10' %>
<% privateip2 = '192.168.200.20' %>
<% privateip3 = '192.168.200.30' %>
---
    db_ssl: false
    db_ssl_ca: ''
    debug: false
    enabled: true
    memcached_port: '11211'
    neutron_metadata_proxy_secret: weakpw
    verbose: 'true'
    cinder_backend_rbd: true
    glance_backend_rbd: true
#  quickstack::pacemaker::cinder:
    backend_eqlx: true
    backend_eqlx_name:
    - eqlx
    - eqlx2
    backend_glusterfs: false
    backend_glusterfs_name: glusterfs
    backend_iscsi: true
    backend_iscsi_name: iscsi
    backend_nfs: true
    backend_nfs_name: nfs
    backend_rbd: false
    backend_rbd_name: rbd
    create_backend_types: true
    eqlx_chap_login:
    - chapadmin
    - chapadmin
    eqlx_chap_password:
    - ''
    eqlx_group_name:
    - group-0
    - group-1
    eqlx_pool:
    - default
    - default2
    eqlx_use_chap:
    - false
    - false
    glusterfs_shares: []
    multiple_backends: true
    nfs_mount_options: ''
    nfs_shares:
    - 192.168.200.100:/mnt/cinder
    rbd_ceph_conf: /etc/ceph/ceph.conf
    rbd_flatten_volume_from_snapshot: false
    rbd_max_clone_depth: '5'
    rbd_pool: volumes
    rbd_secret_uuid: '3b519746-4021-4f72-957e-5b9d991723be'
    rbd_user: volumes
    rpc_backend: cinder.openstack.common.rpc.impl_kombu
    san_ip:
    - ''
    - ''
    san_login:
    - grpadmin
    - grpadmin
    san_password:
    - ''
    - ''
    san_thin_provision:
    - false
    - false
    volume: true
#  quickstack::pacemaker::common:
    fence_ipmilan_address: ''
    fence_ipmilan_expose_lanplus: 'true'
    fence_ipmilan_hostlist: ''
    fence_ipmilan_host_to_address: []
    fence_ipmilan_interval: 60s
    fence_ipmilan_lanplus_options: ''
    fence_ipmilan_password: ''
    fence_ipmilan_username: ''
    fence_xvm_clu_iface: eth2
    fence_xvm_clu_network: ''
    fence_xvm_key_file_password: weakpw
    fence_xvm_manage_key_file: 'false'
    fencing_type: disabled
    #fencing_type: fence_xvm
    pacemaker_cluster_members: <%= privateip1 %> <%= privateip2 %> <%= privateip3 %>
    pacemaker_cluster_name: openstackHA
#  quickstack::pacemaker::galera:
    galera_monitor_password: weakpw
    galera_monitor_username: monitor_user
    mysql_root_password: mysqlrootpw
    wsrep_cluster_members:
    - <%= privateip1 %>
    - <%= privateip2 %>
    - <%= privateip3 %>
    wsrep_cluster_name: galera_cluster
    wsrep_ssl: true
    wsrep_ssl_cert: /etc/pki/galera/galera.crt
    wsrep_ssl_key: /etc/pki/galera/galera.key
    wsrep_sst_method: rsync
    wsrep_sst_password: weakpw
    wsrep_sst_username: sst_user
#  quickstack::pacemaker::glance:
    backend: file
    filesystem_store_datadir: /var/lib/glance/images/
    pcmk_fs_device: 192.168.200.100:/mnt/glance
    pcmk_fs_dir: /var/lib/glance/images/
    pcmk_fs_manage: 'true'
    pcmk_fs_options: ''
    pcmk_fs_type: nfs
    pcmk_swift_is_local: 'false'
    rbd_store_pool: images
    rbd_store_user: images
    sql_idle_timeout: '3600'
    swift_store_auth_address: http://127.0.0.1:5000/v2.0/
    swift_store_key: ''
    swift_store_user: ''
#  quickstack::pacemaker::heat:
#  quickstack::pacemaker::horizon:
    horizon_ca: /etc/ipa/ca.crt
    horizon_cert: /etc/pki/tls/certs/PUB_HOST-horizon.crt
    horizon_key: /etc/pki/tls/private/PUB_HOST-horizon.key
    keystone_default_role: _member_
    secret_key: weakpw
#  quickstack::pacemaker::keystone:
    admin_email: admin@example.com
    admin_password: weakpw
    admin_tenant: admin
    admin_token: weakpw
    ceilometer: 'false'
    cinder: 'true'
    db_type: mysql
    glance: 'true'
    heat: <%= heat %>
    heat_cfn: <%= heat %>
    idle_timeout: '200'
    keystonerc: 'true'
    nova: 'true'
    public_protocol: http
    region: RegionOne
    swift: 'false'
    token_driver: keystone.token.backends.sql.Token
    token_format: PKI
#  quickstack::pacemaker::load_balancer: 
#  quickstack::pacemaker::memcached: 
#  quickstack::pacemaker::neutron:
    core_plugin: neutron.plugins.ml2.plugin.Ml2Plugin
    enable_tunneling: 'true'
    external_network_bridge: br-ex
    ml2_flat_networks:
    - ! '*'
    ml2_mechanism_drivers:
    - openvswitch
    - l2population
    ml2_network_vlan_ranges:
    - yourphysnet:10:50
    ml2_security_group: 'True'
    ml2_tenant_network_types:
    - vxlan
    - vlan
    - gre
    - flat
    ml2_tunnel_id_ranges:
    - 20:100
    ml2_type_drivers:
    - local
    - flat
    - vlan
    - gre
    - vxlan
    ml2_vxlan_group: 224.0.0.1
    ovs_bridge_mappings: []
#    - ext-vlan:br-ex
    ovs_bridge_uplinks: []
#    - br-ex:eth6
    ovs_tunnel_iface: eth6
    ovs_tunnel_network: ''
#    ovs_tunnel_types:
#    - vxlan
    ovs_tunnel_types: []
    ovs_vlan_ranges: ext-vlan:1000:2000
    ovs_vxlan_udp_port: '4789'
    tenant_network_type: vlan
    tunnel_id_ranges: 1:1000
#  quickstack::pacemaker::nova:
    auto_assign_floating_ip: 'True'
    default_floating_pool: nova
    force_dhcp_release: 'false'
    image_service: nova.image.glance.GlanceImageService
    multi_host: 'true'
    rpc_backend: nova.openstack.common.rpc.impl_kombu
    scheduler_host_subset_size: '30'
#  quickstack::pacemaker::params:
    amqp_group: amqp
    amqp_password: weakpw
    amqp_port: '5672'
    amqp_username: openstack
    amqp_vip: 192.168.201.13
    ceilometer_admin_vip: ''
    ceilometer_group: ceilometer
    ceilometer_private_vip: ''
    ceilometer_public_vip: ''
    ceilometer_user_password: weakpw
    ceph_fsid: '904c8491-5c16-4dae-9cc3-6ce633a7f4cc'
    ceph_images_key: 'AQAfHBdUKLnUFxAAtO7WPKQZ8QfEoGqH0CLd7A=='
    ceph_mon_host:
#    - 192.168.7.217
#    - 192.168.7.62
#    - 192.168.7.146
    - <%= privateip1 %>
    - <%= privateip2 %>
    - <%= privateip3 %>
    ceph_mon_initial_members:
    - c1a1
    - c1a2
    - c1a3
    ceph_volumes_key: 'AQAfHBdUsFPTHhAAfqVqPq31FFCvyyO7oaOQXw=='
    ceph_public_network: 192.168.200.0/24
    ceph_cluster_network: 192.168.201.0/24
    ceph_osd_pool_size: '1'
    ceph_osd_pool_default_size: '1'
    ceph_osd_journal_size: '1000'
    cinder_admin_vip: 192.168.201.85
    cinder_db_password: '123456'
    cinder_group: cinder
    cinder_private_vip: 192.168.201.84
    cinder_public_vip: 192.168.201.83
    cinder_user_password: weakpw
    cluster_control_ip: <%= privateip2 %>
    db_group: db
    db_vip: 192.168.201.7
    glance_admin_vip: 192.168.201.25
    glance_db_password: '123456'
    glance_group: glance
    glance_private_vip: 192.168.201.24
    glance_public_vip: 192.168.201.23
    glance_user_password: weakpw
    heat_admin_vip: 192.168.201.115
    heat_auth_encryption_key: weakpw
    heat_cfn_admin_vip: 192.168.201.125
    heat_cfn_enabled: <%= heat %>
    heat_cfn_group: heat_cfn
    heat_cfn_private_vip: 192.168.201.124
    heat_cfn_public_vip: 192.168.201.123
    heat_cfn_user_password: weakpw
    heat_cloudwatch_enabled: <%= heat %>
    heat_db_password: '123456'
    heat_group: heat
    heat_private_vip: 192.168.201.114
    heat_public_vip: 192.168.201.113
    heat_user_password: weakpw
    horizon_admin_vip: 192.168.201.95
    horizon_group: horizon
    horizon_private_vip: 192.168.201.94
    horizon_public_vip: 192.168.201.93
    include_amqp: 'true'
    include_cinder: 'true'
    include_glance: 'true'
    include_heat: '<%= heat %>'
    include_horizon: 'false'
    include_keystone: 'true'
    include_mysql: 'true'
    include_neutron: '<%= neutron %>'
    include_nova: 'true'
    include_swift: 'false'
    keystone_admin_vip: 192.168.201.35
    keystone_db_password: '123456'
    keystone_group: keystone
    keystone_private_vip: 192.168.201.34
    keystone_public_vip: 192.168.201.33
    keystone_user_password: weakpw
    lb_backend_server_addrs:
    - <%= privateip1 %>
    - <%= privateip2 %>
    - <%= privateip3 %>
    lb_backend_server_names:
    - c1a1
    - c1a2
    - c1a3
    loadbalancer_group: loadbalancer
    loadbalancer_vip: 192.168.201.53
    neutron: <%= neutron %>
    neutron_admin_vip: 192.168.201.105
    neutron_db_password: '123456'
    neutron_group: neutron
    neutron_private_vip: 192.168.201.104
    neutron_public_vip: 192.168.201.103
    neutron_user_password: weakpw
    nova_admin_vip: 192.168.201.65
    nova_db_password: '123456'
    nova_group: nova
    nova_private_vip: 192.168.201.64
    nova_public_vip: 192.168.201.63
    nova_user_password: weakpw
    private_iface: eth2
    private_ip: ''
    private_network: ''
    swift_group: swift
    swift_public_vip: 192.168.201.73
    swift_user_password: weakpw
#  quickstack::pacemaker::rabbitmq:
    inet_dist_listen: '35672'
#  quickstack::pacemaker::swift:
    swift_internal_vip: 192.168.111.55
    swift_shared_secret: '123456'
    swift_storage_device: device1
    swift_storage_ips:
    - 192.168.111.14
# quickstack::nova_network::compute:
    amqp_host: 192.168.201.13
    amqp_provider: rabbitmq
#    amqp_provider: qpid
    amqp_ssl_port: '5671'
    auth_host: 192.168.201.33
    # don't matter with false ceilometer
    #ceilometer_metering_secret: ad28a30791819b323769996da7f046e3
    #ceilometer_user_password: 9790e2f72de98c855795ae96d8f4e772
    cinder_backend_gluster: 'false'
    cinder_backend_nfs: 'false'
    glance_host: 192.168.201.23
    mysql_ca: /etc/ipa/ca.crt
    mysql_host: 192.168.201.7
    network_create_networks: true
    network_fixed_range: 10.0.0.0/24
    network_floating_range: 10.0.1.0/24
    network_manager: FlatDHCPManager
    network_network_size: ''
    network_num_networks: 1
    ## commenting out because results in the following in foreman yaml
    ##   network_overrides: !ruby/hash:ActiveSupport::HashWithIndifferentAccess
    ##network_overrides:
    ##  force_dhcp_release: false
    network_private_iface: eth5
    network_private_network: 192.168.203.0
    network_public_iface: eth6
    network_public_network: 192.168.204.0
    nova_db_password: '123456'
    nova_host: 192.168.201.63
    ssl: 'false'
#  quickstack::ceph::config:
    fsid: '904c8491-5c16-4dae-9cc3-6ce633a7f4cc'
    images_key: 'AQAfHBdUKLnUFxAAtO7WPKQZ8QfEoGqH0CLd7A=='
    mon_host:
    - <%= privateip1 %>
    - <%= privateip2 %>
    - <%= privateip3 %>
    mon_initial_members:
    - c1a1
    - c1a2
    - c1a3
    volumes_key: 'AQAfHBdUsFPTHhAAfqVqPq31FFCvyyO7oaOQXw=='
    public_network: 192.168.200.0/24
    cluster_network: 192.168.201.0/24
    osd_pool_size: '1'
    osd_pool_default_size: '1'
    osd_journal_size: '1000'
    rabbit_hosts:
    - <%= privateip1 %>
    - <%= privateip2 %>
    - <%= privateip3 %>
    rabbitmq_use_addrs_not_vip: true
